#!/bin/bash
# ############################################################################################
# File: ........: deployTCEmc
# Language .....: bash 
# Author .......: Sacha Dubois, VMware
# Description ..: Tanzu Demo Hub - Deploy TCE Management Cluster
# ############################################################################################
# BAD


export TANZU_DEMO_HUB=$(cd "$(pwd)/$(dirname $0)"; pwd)
export TDHPATH=$(cd "$(pwd)/$(dirname $0)"; pwd)
export DEBUG=0
export NATIVE=0                ## NATIVE=1 r(un on local host), NATIVE=0 (run within docker)
export DEPLOY_TKG_CLEAN=0
export CMD_EXEC=$(basename $0)
export CMD_ARGS=$*
export TDH_TOOLS=tdh-tools-tce

. $TANZU_DEMO_HUB/functions

usage() {
  echo "USAGE: $0 [oprions] <deployment>"
  echo "            --delete                 # Delete Management Cluster and Jump Server"
  echo "            --debug                  # default (disabled)"
  echo "            --native                 # Use 'native' installed tools instead of the tdh-tools container"
}

listTemplates() {
  echo "TKG CLUSTER TEMPLATES"
  echo "-----------------------------------------------------------------------------------------------------------"
  tmc cluster template list
  echo "-----------------------------------------------------------------------------------------------------------"
}

listDeployments() {
  printf "%-30s %-7s %-7s %-30s %-5s %s\n" "CONFIURATION" "CLOUD" "DOMAIN" "MGMT-CLUSTER" "PLAN" "CONFIGURATION"
  echo "-----------------------------------------------------------------------------------------------------------"

  for deployment in $(ls -1 ${TDHPATH}/deployments/tcemc-*.cfg); do
    . $deployment

    dep=$(basename $deployment)

    printf "%-30s %-7s %-7s %-30s %-5s %s\n" $dep $TDH_TKGMC_INFRASTRUCTURE ${TDH_TKGMC_ENVNAME} "${TDH_TKGMC_NAME}-<TDH_USER>" \
           $TDH_TKGMC_PLAN "$TDH_TKGMC_CONFIG"
  done

  echo "-----------------------------------------------------------------------------------------------------------"
}

listClusters() {
  #cat /tmp/2 | jq -r '.spec | select(.provisionedcluster.accountName == "smidgley-aws").provisionedcluster.accountName'
  cnt=$(tmc cluster list --group sadubois --output json | jq -r '."totalCount"') 
  cnt=$(tmc cluster list --output json | jq -r '."totalCount"') 
  if [ $cnt -gt 0 ]; then
    TMPFILE=/tmp/tdh_listCluster.tmp; rm -f $TMPFILE

    echo "NAME                 KUBERNETES           PROVIDER   CREDENTIALS          REGION          STATE"
    echo "-----------------------------------------------------------------------------------------------------------"

    tmc cluster list --group $TMC_CLUSTER_GROUP --output json > $TMPFILE
    tmc cluster list --output json > $TMPFILE
    for cln in $(jq -r '.clusters[] | select(.status.type == "PROVISIONED").fullName.name' $TMPFILE | head -5); do
      ver=$(jq -r --arg cluster "$cln" '.clusters[] | select(.fullName.name == $cluster)' $TMPFILE | \
            jq -r '.spec.provisionedcluster.version')
      acc=$(jq -r --arg cluster "$cln" '.clusters[] | select(.fullName.name == $cluster)' $TMPFILE | \
            jq -r '.spec.provisionedcluster.accountName')
      cpv=$(jq -r --arg cluster "$cln" '.clusters[] | select(.fullName.name == $cluster)' $TMPFILE | \
            jq -r '.status.agent.metadata.cloudProvider')
      reg=$(jq -r --arg cluster "$cln" '.clusters[] | select(.fullName.name == $cluster)' $TMPFILE | \
            jq -r '.status.agent.metadata.region')
      stt=$(jq -r --arg cluster "$cln" '.clusters[] | select(.fullName.name == $cluster)' $TMPFILE | \
            jq -r '.status.status.state.state')

      printf "%-20s %-20s %-10s %-20s %-15s %-10s\n" $cln $ver $cpv $acc $reg $stt

    done


#    tmc cluster list --output json | jq -r '.clusters[1] | [.fullName.name,.spec.provisionedcluster.version]'

#  tmc cluster list --group $TMC_CLUSTER_GROUP
  echo "-----------------------------------------------------------------------------------------------------------"

    # --- CLEANUP ---
    rm -f $TMPFILE
  fi
}

while [ "$1" != "" ]; do
  case $1 in
    --delete)      DEPLOY_TKG_CLEAN=1;;
    --debug)       DEBUG=1;;
    --native)      NATIVE=1;;
    *)             DEPLOY_TKG_TEMPLATE=$1;;
  esac
  shift
done

if [ "${DEPLOY_TKG_TEMPLATE}" == "" ]; then
  listDeployments
  usage; exit 0
fi

# --- VERIFY DEPLOYMENT ---
if [ ! -f ${TDHPATH}/deployments/${DEPLOY_TKG_TEMPLATE} ]; then
  echo "ERROR: Deployment file $DEPLOY_TKG_TEMPLATE can not be found in ${TDHPATH}/deployments"
  exit 1
else
  . ${TDHPATH}/deployments/${DEPLOY_TKG_TEMPLATE}
fi

# --- CHECK ENVIRONMENT VARIABLES ---
if [ -f ~/.tanzu-demo-hub.cfg ]; then
  . ~/.tanzu-demo-hub.cfg
fi

export TDH_DEPLOYMENT_ENV_NAME=$TDH_TKGMC_INFRASTRUCTURE
export TKG_CONFIG=~/.tanzu-demo-hub/$TDH_TKGMC_CONFIG

cleanupEnvironment() {
  # --- CHECK FOR WORKLOAD CLUSTERS ---
  tanzu cluster list >/dev/null 2>&1; ret=$?
  if [ $ret -eq 0 ]; then
    cnt=$(tanzu cluster list 2>/dev/null | sed '1d' | wc -l | sed 's/  *//g') 
    if [ $cnt -gt 0 ]; then
      tanzu cluster list
      messageLine
      echo "ERROR: TCE Workload Clusters are still running, please delete them first."
      for n in $(tanzu cluster list | sed '1d' | awk '{ print $1 }'); do
        echo "       => tanzu cluster delete $n -y"
      done
      exit 1
    fi
  fi

  cleanKindCluster

  cnt=$(tanzu cluster list --include-management-cluster 2>/dev/null | grep -c " $TDH_TKGMC_NAME-$TDH_USER") 
  if [ $cnt -gt 0 ]; then 
    messageTitle "Deleting Management Cluster ($TDH_TKGMC_NAME-$TDH_USER)"
    if [ $DEBUG -gt 0 ]; then
      tanzu management-cluster delete ${TDH_TKGMC_NAME}-$TDH_USER -y; ret=$?
      messageLine
    else
      tanzu management-cluster delete ${TDH_TKGMC_NAME}-$TDH_USER -y > /dev/null 2>&1; ret=$?
    fi
    
    if [ $ret -ne 0 ]; then 
      echo "ERROR: failed to delete management cluster ($TDH_TKGMC_NAME-$TDH_USER)"
      if [ "$NATIVE" == "0" ]; then
        echo "    => tools/$TDH_TOOLS.sh"
        echo "       tdh-tools:/$ tanzu management-cluster delete $TDH_TKGMC_NAME-$TDH_USER -y"
        echo "       tdh-tools:/$ exit"
      else
        echo "    => tanzu management-cluster delete $TDH_TKGMC_NAME-$TDH_USER -y"
      fi
  
      exit 1
    fi
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
    TERRAFORM_PATH=$HOME/.tanzu-demo-hub/terraform/aws
    if [ ! -d $TERRAFORM_PATH ]; then 
      mkdir -p $TERRAFORM_PATH
      cp -r ${TDHPATH}/terraform/aws $HOME/.tanzu-demo-hub/terraform
    fi

    TDH_TERRAFORM_TFVARS=$TERRAFORM_PATH/terraform_${TDH_TKGMC_ENVNAME}.tfvars
    TDH_TERRAFORM_TFSTATE=$TERRAFORM_PATH/terraform_${TDH_TKGMC_ENVNAME}.tfstate

    messageTitle "Deleting Jump Host (jump-${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN})"
     
    cnt=0; ret=1
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      if [ $DEBUG -gt 0 ]; then
        terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
                            -var-file=$TDH_TERRAFORM_TFVARS -auto-approve; ret=$?
        messageLine
      else
        terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
                            -var-file=$TDH_TERRAFORM_TFVARS -auto-approve > /dev/null 2>&1; ret=$?
      fi
      [ $ret -eq 0 ] && break
      let cnt=cnt+1
      sleep 60
    done

    if [ $ret -ne 0 ]; then
      echo "ERROR: terraform destroy failed"
      if [ "$NATIVE" == "0" ]; then
        echo "    => tools/$TDH_TOOLS.sh"
        echo "       tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
        echo "                       -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
        echo "       tdh-tools:/$ exit"
      else
        echo "       => terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
        echo "                    -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
      fi

      exit 1
    fi
  fi
}

checkKeyPairs() {
  messageTitle "SSH Key Pairs"

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ]; then
    if [ ! -f ~/.tanzu-demo-hub/KeyPair-Azure.pem ]; then 
      # GENERATE INGRES FILES
      rm -f ~/.tanzu-demo-hub/KeyPair-Azure.pem ~/.tanzu-demo-hub/KeyPair-Azure.pub
      ssh-keygen -t rsa -b 4096 -f ~/.tanzu-demo-hub/KeyPair-Azure -P "" > /dev/null 2>&1
      mv ~/.tanzu-demo-hub/KeyPair-Azure ~/.tanzu-demo-hub/KeyPair-Azure.pem
#    else
      # COMPATE KEYS
      #LOCALSSH=$(cat ~/.tanzu-demo-hub/KeyPair-Azure.pub | base64 | tr -d ‘\r\n’)
      #CONFIGSSH=$(egrep "^AZURE_SSH_PUBLIC_KEY_B64:" ${TDHPATH}/config/${TDH_TKGMC_CONFIG} | awk '{ print $2 }')

      #if [ "${LOCALSSH} != ${CONFIGSSH}" ]; then
      #  gsed -i "s/^\(AZURE_SSH_PUBLIC_KEY_B64:\) .*$/\1 $LOCALSSH/g" ${TDHPATH}/config/${TDH_TKGMC_CONFIG}
      #fi
    fi
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
    SSH_KEY_NAME=tanzu-demo-hub
    SSH_KEY_FILE=$HOME/.tanzu-demo-hub/KeyPair-${SSH_KEY_NAME}-${AWS_REGION}.pem
    messagePrint " ▪ KeyPair Name" "$SSH_KEY_NAME"
    messagePrint " ▪ KeyPair File" "$SSH_KEY_FILE"

    # --- GENERATING KEY PAIR ---
    if [ ! -f $SSH_KEY_FILE ]; then 
      messagePrint " ▪ Generating KeyPair" "SSH_KEY_FILE"
      aws ec2 --region=$AWS_REGION delete-key-pair --key-name $SSH_KEY_NAME > /dev/null 2>&1
      aws ec2 --region=$AWS_REGION create-key-pair --key-name $SSH_KEY_NAME | \
         jq -r '.KeyMaterial' > $SSH_KEY_FILE
      chmod 600 $SSH_KEY_FILE
    fi

    if [ ! -d ~/.tanzu-demo-hub ] ; then mkdir ~/.tanzu-demo-hub; fi
  
    # --- VERIFY KEY-PAIR ---
    key=$(aws ec2 --region=$AWS_REGION describe-key-pairs | \
          jq -r --arg key "$SSH_KEY_NAME" '.KeyPairs[] | select(.KeyName == $key).KeyFingerprint')
  
    # --- CREATE ONE IF IT DOES NOT EXIST ---
    if [ "${key}" == "" ]; then 
      aws ec2 --region=$AWS_REGION create-key-pair --key-name $SSH_KEY_NAME | \
         jq -r '.KeyMaterial' > $SSH_KEY_FILE
      chmod 600 $SSH_KEY_FILE
      key=$(aws ec2 --region=$AWS_REGION describe-key-pairs | \
            jq -r --arg key "$SSH_KEY_NAME" '.KeyPairs[] | select(.KeyName == $key).KeyFingerprint')
    fi

    if [ -f "${SSH_KEY_FILE}" ]; then
      # openssl pkcs8 -in $SSH_KEY_FILE -inform PEM -outform DER -topk8 -nocrypt | openssl sha1 -c
      # Linux: (stdin)= 60:db:70:2a:ce:0a:c1:ed:79:07:1c:be:9b:18:51:e9:78:84:7f:17
      # MAC:   60:db:70:2a:ce:0a:c1:ed:79:07:1c:be:9b:18:51:e9:78:84:7f:17
      if [ "$(uname)" == "Linux" ]; then 
        kfp=$(openssl pkcs8 -in $SSH_KEY_FILE -inform PEM -outform DER -topk8 -nocrypt | openssl sha1 -c | awk '{ print $2 }')
      else
        kfp=$(openssl pkcs8 -in $SSH_KEY_FILE -inform PEM -outform DER -topk8 -nocrypt | openssl sha1 -c)
      fi
    
      messagePrint " ▪ Verify KeyPair Fingerpring" "$kfp"
      if [ "${key}" != "${kfp}" ]; then
        messagePrint " ▪ KeyPair Fingerpring not valid, regenerating" "$SSH_KEY_NAME"
        aws ec2 --region=$AWS_REGION delete-key-pair --key-name $SSH_KEY_NAME > /dev/null
        aws ec2 --region=$AWS_REGION create-key-pair --key-name $SSH_KEY_NAME | \
           jq -r '.KeyMaterial' > $SSH_KEY_FILE
        chmod 600 $SSH_KEY_FILE
      fi
    fi
  fi
}

configureLetsEnscript() {
  ##############################################################################################
  ################################ GENERATING TLS CERTIFICATES #################################
  ##############################################################################################

  CERTS_GENERATE_NEW=false
  domain="${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN}"

  if [ -d $HOME/.tanzu-demo-hub/certificates/$domain -a -f $HOME/.tanzu-demo-hub/certificates/$domain/privkey.pem ]; then
    messageTitle "Install Certificate for domain ($domain)"
    $SSH_COMMAND -n "mkdir -p $SSH_HOME/tanzu-demo-hub/certificates"
    $SCP_COMMAND $HOME/.tanzu-demo-hub/certificates/$domain/* ${SSH_USER}@${SSH_HOST}:~/tanzu-demo-hub/certificates > /dev/null 2>&1
  fi

  CERTS_INSTALLED=$($SSH_COMMAND -n "[ -f ~/tanzu-demo-hub/certificates/privkey.pem ] && echo true || echo false")

  if [ "${CERTS_INSTALLED}" == "true" ]; then
    messageTitle "Validate Certificates for domain ($domain)"
    $SCP_COMMAND $HOME/.tanzu-demo-hub/certificates/$domain/* ${SSH_USER}@${SSH_HOST}:~/tanzu-demo-hub/certificates > /dev/null 2>&1

    CERTS_ENDDATE=$($SSH_COMMAND -n "openssl x509 -noout -in ~/tanzu-demo-hub/certificates/cert.pem -enddate | awk -F'=' '{ print \$2 }'")
    CERTS_EXPIRED=$($SSH_COMMAND -n "openssl x509 -noout -in ~/tanzu-demo-hub/certificates/cert.pem -checkend 3600 > /dev/null 2>&1; echo \$?")

    if [ $CERTS_EXPIRED -eq 0 ]; then
      messagePrint " ▪ Certificate Expiratation Data:" "$CERTS_ENDDATE"
    else
      messagePrint " ▪ Certificate Expiratation Data:" "$CERTS_ENDDATE [>>> *EXPIRED* <<<]"
      CERTS_GENERATE_NEW=true
    fi
  else
    CERTS_GENERATE_NEW=true
  fi

  if [ "${CERTS_GENERATE_NEW}" == "true" ]; then
    messageTitle "Generate Certificates for domain ($domain)"
    route53createHostedZone $domain

    echo "-------------------------------------- GENERATE LET'S-ENCRYPT CERTIFICATES -------------------------------------"
    typ=$(echo $domain | egrep -c "aztkg|awstkg|gcptkg|vstkg")
    if [ $typ -ne 0 ]; then
      messageTitle "Generate Certificate for TCE Domains ($domain)"
      $SSH_COMMAND -n "sudo certbot certonly --dns-route53 -d '*.$domain' -m sadubois@pivotal.io --agree-tos -n --expand"
      if [ $? -ne 0 ]; then
        echo "ERROR: failed to generate certificate. There are probably to many cert requests happends and a limit reached"
        echo "       Try it again after some hours or search *.$domain in https://crt.sh/"
        exit 1
      fi
    fi

    # --- GET A COPY OF THE CERTIFICATES BACK ---
    [ ! -d $HOME/.tanzu-demo-hub/certificates/$domain ] && mkdir -p $HOME/.tanzu-demo-hub/certificates/$domain

    $SSH_COMMAND -n "[ -d /etc/letsencrypt/live ] && sudo chmod -R a+r /etc/letsencrypt/live /etc/letsencrypt/archive"
    $SSH_COMMAND -n "[ -d /etc/letsencrypt/live ] && sudo chmod 777 /etc/letsencrypt/live /etc/letsencrypt/live/$domain"
    $SSH_COMMAND -n "[ -d /etc/letsencrypt/archive ] && sudo chmod 777 /etc/letsencrypt/archive /etc/letsencrypt/archive/$domain"
    $SSH_COMMAND -n "[ ! -d $SSH_HOME/tanzu-demo-hub/certificates/$domain ] && mkdir -p $SSH_HOME/tanzu-demo-hub/certificates"
    $SSH_COMMAND -n "[ -d /etc/letsencrypt/live/$domain ] && cp /etc/letsencrypt/live/$domain/* ~/tanzu-demo-hub/certificates"

    messageTitle " Copy new certificates from jump to local ./certificates/$domain"
    cnt=0; ret=1
    while [ ! -f ./certificates/$domain/fullchain.pem ]; do
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/tanzu-demo-hub/certificates/* $HOME/.tanzu-demo-hub/certificates/$domain/ > /dev/null 2>&1; ret=$?
      [ $cnt -gt 5 ] && break

      sleep 10
      let cnt=cnt+1
    done

    if [ $ret -ne 0 ]; then 
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/tanzu-demo-hub/certificates/* $HOME/.tanzu-demo-hub/certificates/$domain/ 
      echo "ERROR: failed to copy SSL/TLS cert from jumphost"
      echo "       => SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/tanzu-demo-hub/certificates/* $HOME/.tanzu-demo-hub/certificates/$domain/ "
      exit
    fi

    echo "----------------------------------------------------------------------------------------------------------------"
  fi
}

createJumpHost() {
  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ]; then
    JUMP_HOST="jump-${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN}"
    messageTitle "AWS Jump-Server ($JUMP_HOST)"

    TERRAFORM_PATH=$HOME/.tanzu-demo-hub/terraform/aws
    if [ ! -d $TERRAFORM_PATH ]; then
      mkdir -p $TERRAFORM_PATH
    fi

    cp -r ${TDHPATH}/terraform/aws $HOME/.tanzu-demo-hub/terraform

    TDH_TERRAFORM_TFVARS=${TERRAFORM_PATH}/terraform_${TDH_TKGMC_ENVNAME}.tfvars
    TDH_TERRAFORM_TFSTATE=${TERRAFORM_PATH}/terraform_${TDH_TKGMC_ENVNAME}.tfstate
    TDH_TERRAFORM_STATE=${TERRAFORM_PATH}/terraform_${TDH_TKGMC_ENVNAME}.state
    KEY_NAME=tanzu-demo-hub

    ins=$(aws ec2 --region=$AWS_REGION describe-instances --filters "Name=instance-state-name,Values=pending,running,stopped" \
         Name=tag:Owner,Values="tdh-${TDH_TKGMC_ENVNAME}" | jq -r ".Reservations[].Instances[].InstanceId" | head -1)
    if [ "${ins}" == "" ]; then
      messagePrint " ▪ Cleaning up leftover terraform deployments" "${TERRAFORM_PATH}"
      echo "aws_region = \"$AWS_REGION\""                          >  $TDH_TERRAFORM_TFVARS
      echo "owner = \"tdh-$TDH_TKGMC_ENVNAME\""                    >> $TDH_TERRAFORM_TFVARS
      echo "aws_region_az = \"$az\""                               >> $TDH_TERRAFORM_TFVARS
      echo "key_pair = \"$KEY_NAME\""                              >> $TDH_TERRAFORM_TFVARS

      if [ -x /usr/local/bin/terraform -o -x /usr/bin/terraform ]
      then
	if [ -f $TDH_TERRAFORM_TFSTATE ]
	then
	  if [ $DEBUG -gt 0 ]; then
	    echo "--------------------------------------------------------------------------------------------------------------"
	    terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
		      -var-file=$TDH_TERRAFORM_TFVARS -auto-approve; ret=$? 
	    echo "--------------------------------------------------------------------------------------------------------------"
	  else
	    terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \
		      -var-file=$TDH_TERRAFORM_TFVARS -auto-approve > /dev/null 2>&1; ret=$? 
	  fi

	  if [ $ret -ne 0 ]; then
	    echo "ERROR: terraform destroy failed"
            if [ "$NATIVE" == "0" ]; then
              echo "       => tools/$TDH_TOOLS.sh"
              echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
	      echo "                                 -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
              echo "          tdh-tools:/$ exit"
            else
	      echo "       => terraform -chdir=${TERRAFORM_PATH} destroy -state=$TDH_TERRAFORM_TFSTATE \\"
	      echo "                    -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
            fi
	    exit
	  fi
	fi
      else
        echo "ERROR: HashiCorp terraform has not been installed, download it from https://www.terraform.io"
        echo "       and install it in /usr/local/bin/terraform"; exit 0
      fi

      #aws ec2 --region=$AWS_REGION describe-key-pairs --key-names ${KEY_NAME} > /dev/null 2>&1; ret=$?
      #if [ $ret -ne 0 ]; then
      #  messagePrint " ▪ Creating Key Pair" "${KEY_NAME}"
      #  aws ec2 --region=$AWS_REGION create-key-pair --key-name ${KEY_NAME} \
      #        --query 'KeyMaterial' --output text > ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-$AWS_REGION.pem 2>/dev/null
      #  chmod 600 ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-${AWS_REGION}.pem
      #  if [ $? -ne 0 ]; then
      #    echo "ERROR: Creating Key Pairs failed"
      #    if [ "$NATIVE" == "0" ]; then
      #      echo "       => tools/$TDH_TOOLS.sh"
      #      echo "          tdh-tools:/$ aws ec2 --region=$AWS_REGION create-key-pair --key-name ${KEY_NAME}  \\"
      #      echo "                         --query 'KeyMaterial' --output text > ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-${AWS_REGION}.pem"
      #      echo "          tdh-tools:/$ exit"
      #    else
      #      echo "       => aws ec2 --region=$AWS_REGION create-key-pair --key-name ${KEY_NAME}  \\"
      #      echo "                  --query 'KeyMaterial' --output text > ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-${AWS_REGION}.pem"
      #    fi
      #
      #    exit 1
      #  fi
      #else
      #  messagePrint " ▪ Key Pair exists on AWS" "${KEY_NAME}"
      #fi

      messagePrint " ▪ Deploy vSphere Jump-Server with (terraforms)" "$JUMP_HOST"
      messagePrint " ▪ Creating Variable file" "${TERRAFORM_PATH}/terraform.tfvars"

      availability_zone=$(echo $AWS_PRIMARY_AZ | sed 's/^.*\(.\)$/\1/g') 
      if [ "$availability_zone" != "a" -a "$availability_zone" != "b" -a "$availability_zone" != "c" ]; then 
        echo "ERROR: Availability Zone of an AWS Region should be 'a', 'b' or 'c'"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/$TDH_TOOLS.sh"
          echo "          tdh-tools:/$ aws ec2 --region=$AWS_REGION describe-availability-zones --output text"
          echo "          tdh-tools:/$ exit"
        else
          echo "       => aws ec2 --region=$AWS_REGION describe-availability-zones --output text"
        fi

        exit 1
      fi

      echo "aws_region = \"$AWS_REGION\""                          >  $TDH_TERRAFORM_TFVARS
      echo "owner = \"tdh-$TDH_TKGMC_ENVNAME\""                    >> $TDH_TERRAFORM_TFVARS
      echo "aws_region_az = \"$availability_zone\""                >> $TDH_TERRAFORM_TFVARS
      echo "key_pair = \"$KEY_NAME\""                              >> $TDH_TERRAFORM_TFVARS

      if [ -x /usr/local/bin/terraform -o -x /usr/bin/terraform ]; then
        if [ $DEBUG -gt 0 ]; then 
          echo "--------------------------------------------------------------------------------------------------------------"
          echo "=> terraform -chdir=${TERRAFORM_PATH} init"
          echo "--------------------------------------------------------------------------------------------------------------"
          terraform -chdir=${TERRAFORM_PATH} init; ret=$?
        else
          messagePrint " ▪ Terraform (init)" "${TERRAFORM_PATH}"
          terraform -chdir=${TERRAFORM_PATH} init > /dev/null 2>&1; ret=$?
        fi

        if [ $ret -ne 0 ]; then 
          echo "ERROR: terraform init failed"
          if [ "$NATIVE" == "0" ]; then
            echo "       => tools/$TDH_TOOLS.sh"
            echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} init"
            echo "          tdh-tools:/$ exit"
          else
            echo "       => terraform -chdir=${TERRAFORM_PATH} init"
          fi
          exit
        fi

        if [ $DEBUG -gt 0 ]; then
          echo "--------------------------------------------------------------------------------------------------------------"
          echo "=> terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \
                    -out jump -state=$TDH_TERRAFORM_TFSTATE"
          echo "--------------------------------------------------------------------------------------------------------------"
          terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \
                    -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE; ret=$?
        else
          messagePrint " ▪ Terraform (plan)" "${TERRAFORM_PATH}"
          terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \
                    -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE > /dev/null 2>&1; ret=$?
        fi

        if [ $ret -ne 0 ]; then 
          echo "ERROR: terraform plan failed"
          if [ "$NATIVE" == "0" ]; then
            echo "       => tools/$TDH_TOOLS.sh"
            echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \\"
            echo "                         -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE"
            echo "          tdh-tools:/$ exit"
          else
            echo "       => terraform -chdir=${TERRAFORM_PATH} plan -var-file=$TDH_TERRAFORM_TFVARS \\"
            echo "                    -out "jump-$TDH_TKGMC_ENVNAME" -state=$TDH_TERRAFORM_TFSTATE"
          fi

          exit 1
        fi

        if [ $DEBUG -gt 0 ]; then
          echo "--------------------------------------------------------------------------------------------------------------"
          echo "=> terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE \"jump-$TDH_TKGMC_ENVNAME\""
          terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE "jump-$TDH_TKGMC_ENVNAME"; ret=$?
        else
          messagePrint " ▪ Terraform (apply)" "${TERRAFORM_PATH}"
          terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE "jump-$TDH_TKGMC_ENVNAME" > /dev/null 2>&1; ret=$?
        fi

        if [ $ret -ne 0 ]; then
          echo "1ERROR: terraform apply failed"
          if [ "$NATIVE" == "0" ]; then
            echo "       => tools/$TDH_TOOLS.sh"
            echo "          tdh-tools:/$ terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE \"jump-$TDH_TKGMC_ENVNAME\""
            echo "          tdh-tools:/$ exit"
          else
            echo "       => terraform -chdir=${TERRAFORM_PATH} apply -state=$TDH_TERRAFORM_TFSTATE \"jump-$TDH_TKGMC_ENVNAME\""
          fi

          exit 1
        fi

        #terraform -chdir=$TERRAFORM_PATH destroy -state=$TDH_TERRAFORM_TFSTATE -var-file=$TDH_TERRAFORM_TFVARS -auto-approve
      else
        echo "ERROR: HashiCorp terraform has not been installed, download it from https://www.terraform.io"
        echo "       and install it in /usr/local/bin/terraform"; exit 0
      fi

      # --- WAIT FOR INSTANCE TO COME ONLINE ---
      ins=""; cnt=0
      while [ "$ins" == "" -a $cnt -lt 5 ]; do
        ins=$(aws ec2 --region=$AWS_REGION describe-instances --filters "Name=instance-state-name,Values=pending,running,stopped" \
           Name=tag:Owner,Values="tdh-${TDH_TKGMC_ENVNAME}" | jq -r ".Reservations[].Instances[].InstanceId" | head -1)

        sleep 20
        let cnt=cnt+1
      done

      if [ "$ins" == "" ]; then 
        echo "ERROR: Failed to get Instance ID of new crewated Jump VM"
        if [ "$NATIVE" == "0" ]; then
          echo "       => tools/$TDH_TOOLS.sh"
          echo "          tdh-tools:/$ aws ec2 --region=$AWS_REGION describe-instances \\"
          echo "                               --filters \"Name=instance-state-name,Values=pending,running,stopped\" \\"
          echo "                               Name=tag:Owner,Values=\"tdh-${TDH_TKGMC_ENVNAME}\""
          echo "          tdh-tools:/$ exit"
        else
          echo "       => aws ec2 --region=$AWS_REGION describe-instances \\"
          echo "                  --filters \"Name=instance-state-name,Values=pending,running,stopped\" \\"
          echo "                  Name=tag:Owner,Values=\"tdh-${TDH_TKGMC_ENVNAME}\""
        fi

        exit 1
      fi

      stt=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
         jq -r ".Reservations[].Instances[].State.Name")
      dns=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
         jq -r ".Reservations[].Instances[].PublicDnsName")
      pip=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
         jq -r ".Reservations[].Instances[].PublicIpAddress")

      ZONE_ID=$(aws route53 list-hosted-zones-by-name --dns-name ${AWS_HOSTED_DNS_DOMAIN} | jq -r '.HostedZones[0].Id')
      ZONE_ID_STR=$(echo "${ZONE_ID}" | awk -F'/' '{ print $NF }')
      messagePrint " ▪ DNS Zone (${AWS_HOSTED_DNS_DOMAIN}:" "zone managed by route53"
      messagePrint " ▪ Updating Zone Record for ($JUMP_HOST)" "$pip"

      # --- CREATE HOSTED ZONE ---
      route53createHostedZone $TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN

      # --- UPDATE DNS DOMAIN ---
      messagePrint " ▪ Updating Zone Record for ($JUMP_HOST)" "$pip"
      route53setDNSrecord "$pip" "$JUMP_HOST" "$AWS_HOSTED_DNS_DOMAIN"

      messagePrint " ▪ Updating Zone Record for (jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN)" "$pip"
      route53setDNSrecord "$pip" "jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN" "$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN"
    fi

    ins=$(aws ec2 --region=$AWS_REGION describe-instances --filters "Name=instance-state-name,Values=pending,running,stopped" \
       Name=tag:Owner,Values="tdh-${TDH_TKGMC_ENVNAME}" | jq -r ".Reservations[].Instances[].InstanceId" | head -1)
    stt=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
       jq -r ".Reservations[].Instances[].State.Name")
    dns=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
       jq -r ".Reservations[].Instances[].PublicDnsName")
    pip=$(aws ec2 --region=$AWS_REGION describe-instances --instance-ids $ins | \
       jq -r ".Reservations[].Instances[].PublicIpAddress")

    messageTitle "Verify AWS Jump-Server"
    messagePrint " ▪ AWS Instance ID" "$ins"
    messagePrint " ▪ Jump Server Hostname" "$JUMP_HOST"
    messagePrint " ▪ Jump Server Status" "$stt"
    messagePrint " ▪ Jump Server IP Address" "$pip"
    messagePrint " ▪ Destroy Command" "terraform destroy"

    messageLine
    echo "terraform -chdir=$TERRAFORM_PATH destroy \\"
    echo "          -state=$TDH_TERRAFORM_TFSTATE \\"
    echo "          -var-file=$TDH_TERRAFORM_TFVARS -auto-approve"
    messageLine

    sed -in "/$JUMP_HOST/d" ~/.ssh/known_hosts
    SSH_USER=ubuntu
    SSH_HOME=/home/ubuntu
    SSH_HOST=$JUMP_HOST
    SSH_OPTIONS="-o StrictHostKeyChecking=no -o RequestTTY=yes -o ServerAliveInterval=30"
    SCP_OPTIONS="-o StrictHostKeyChecking=no"
    SSH_COMMAND="ssh -q $SSH_OPTIONS -i ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-$AWS_REGION.pem ${SSH_USER}@${SSH_HOST}"
    SCP_COMMAND="scp -r $SCP_OPTIONS -i ~/.tanzu-demo-hub/KeyPair-${KEY_NAME}-$AWS_REGION.pem"

    messagePrint " ▪ Wait for SSH to be ready" "< 5m"
    # --- WAIT UNTIL SSH DEAMON IS READY NO JUMPHOST ----
    ret=1
    while [ $ret -ne 0 ]; do
      $SSH_COMMAND -n id > /dev/null 2>&1; ret=$?
      [ $ret -ne 0 ] && sleep 10
    done
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" -a "$TDH_TKGMC_CREATE_JUMPHOST" == "false" ]; then
    JUMP_HOST="${VSPHERE_JUMPHOST_NAME}"
    SSH_USER="${VSPHERE_JUMPHOST_USER}"
    SSH_OPTIONS="-o StrictHostKeyChecking=no -o RequestTTY=yes -o ServerAliveInterval=240"
    SSH_PRIVATE_KEY=$VSPHERE_SSH_PRIVATE_KEY_FILE
    SSH_COMMAND="ssh -q $SSH_OPTIONS -i ${SSH_PRIVATE_KEY} ${SSH_USER}@${JUMP_HOST}"

    messageTitle "Verify vSphere Jump-Server ($JUMP_HOST)"
    messagePrint " ▪ Wait for SSH to be ready" "< 3m"

    # --- WAIT UNTIL SSH DEAMON IS READY NO JUMPHOST ----
    ret=1
    while [ $ret -ne 0 ]; do
      $SSH_COMMAND -n id > /dev/null 2>&1; ret=$?
      [ $ret -ne 0 ] && sleep 10
    done

    messageTitle "Verify SuDO Access" "$JUMP_HOST"
    verify_datacenter
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" -a "$TDH_TKGMC_CREATE_JUMPHOST" == "true" ]; then
    VSPHERE_JUMPHOST_NAME=jump.$VSPHERE_DNS_DOMAIN

    JUMP_HOST="${VSPHERE_JUMPHOST_NAME}"
    SSH_USER=ubuntu
    SSH_OPTIONS="-o StrictHostKeyChecking=no -o RequestTTY=yes -o ServerAliveInterval=240"
    SSH_PRIVATE_KEY=$VSPHERE_SSH_PRIVATE_KEY_FILE
    SSH_COMMAND="ssh -q $SSH_OPTIONS -i ${SSH_PRIVATE_KEY} ${SSH_USER}@${JUMP_HOST}"
    SSH_USER=ubuntu

    # --- TEST IF JUMP HOST IS ALREADY DEPLOYED
    $SSH_COMMAND -n "hostname > /dev/null 2>&1"; ret=$?
    if [ "$ret" != 0 ]; then   
      # --- PACKER CREATE JUMP TEMPLATE ---
      messageTitle "Crreate vSphere Jump-Server ($JUMP_HOST) with (packer)"
      messagePrint " ▪ Using Ubuntu Packer Config" "${TDHPATH}/packer/ubuntu.json"
      messagePrint " ▪ Generating Packer Config" "/tmp/jump.json"

      verify_datacenter 

      cat ${TDHPATH}/packer/jump_variables.json | sed -e "s/XXX_VSPHERE_SERVER_XXX/$VSPHERE_VCENTER_SERVER/g" \
         -e "s/XXX_VSPHERE_PASSWORD_XXX/$VSPHERE_VCENTER_PASSWORD/g"  -e "s/XXX_VSPHERE_DATACENTER_XXX/$VSPHERE_DATACENTER/g" \
         -e "s/XXX_VSPHERE_ADMIN_XXX/$VSPHERE_VCENTER_ADMIN/g"  -e "s/XXX_VSPHERE_DATACENTER_XXX/$VSPHERE_DATACENTER/g" \
         -e "s/XXX_VSPHERE_DATASTORE_XXX/$VSPHERE_DATASTORE/g" -e "s/XXX_VSPHERE_CLUSTER_XXX/$VSPHERE_CLUSTER/g"\
         -e "s/XXX_VSPHERE_WAN_NETWORK_XXX/$VSPHERE_WAN_NETWORK/g" \
         -e "s/XXX_VSPHERE_MANAGEMENT_NETWORK_XXX/$VSPHERE_NETWORK/g" > /tmp/jump.json

      messagePrint " ▪ Generating Preseed Config" "/tmp/preseed.cfg"
      VSPHERE_SSH_PUBLIC_KEY=$(cat $VSPHERE_SSH_PUBLIC_KEY_FILE)
      echo "    in-target /bin/sh -c \"echo '$VSPHERE_SSH_PUBLIC_KEY' >> /home/ubuntu/.ssh/authorized_keys\"; " > /tmp/snipset.txt
      cat ${TDHPATH}/packer/jump_preseed.cfg | sed -e '/XXX_SSHKEY_XXX/r /tmp/snipset.txt' -e '/XXX_SSHKEY_XXX/d' > /tmp/preseed.cfg

      if [ -x /usr/local/bin/packer ]; then
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> packer build -var-file=/tmp/jump.json ${TDHPATH}/packer/ubuntu.json"
        echo "--------------------------------------------------------------------------------------------------------------"
        packer build -var-file=/tmp/jump.json ${TDHPATH}/packer/ubuntu.json | sed '/^$/d'
        echo "--------------------------------------------------------------------------------------------------------------"
      else
        echo "ERROR: HashiCorp Packer has not been installed, download it from https://www.packer.io/downloads" 
        echo "       and install it in /usr/local/bin/packer"; exit 0
      fi

      messagePrint "Deploy vSphere Jump-Server with (terraforms)" "$JUMP_HOST"
      messagePrint " ▪ Creating Variable file" "/tmp/terraform.tfvars"
      echo "vsphere_user = \"$VSPHERE_VCENTER_ADMIN\""             >  /tmp/terraform.tfvars
      echo "vsphere_password = \"$VSPHERE_VCENTER_PASSWORD\""      >> /tmp/terraform.tfvars
      echo "vsphere_server = \"$VSPHERE_SERVER\""                  >> /tmp/terraform.tfvars
      echo "vsphere_datacenter = \"$VSPHERE_DATACENTER\""          >> /tmp/terraform.tfvars
      echo "vsphere_datastore = \"$VSPHERE_DATASTORE\""            >> /tmp/terraform.tfvars
      echo "vsphere_compute_cluster = \"$VSPHERE_CLUSTER\""        >> /tmp/terraform.tfvars
      echo "#vsphere_resource_pool = \"cluster/Resources\""        >> /tmp/terraform.tfvars
      echo "vsphere_network = \"$VSPHERE_NETWORK\""                >> /tmp/terraform.tfvars
      echo "vsphere_virtual_machine_template = \"jump_template\""  >> /tmp/terraform.tfvars
      echo "vsphere_virtual_machine_name = \"jump\""               >> /tmp/terraform.tfvars
      echo "root_password = \"root\""                              >> /tmp/terraform.tfvars

      if [ -x /usr/local/bin/terraform -o -x /usr/bin/terraform ]; then
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> terraform -chdir=${TERRAFORM_PATH} init"
        echo "--------------------------------------------------------------------------------------------------------------"
        terraform -chdir=${TERRAFORM_PATH} init
  
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> terraform -chdir=${TDHPATH}/terraform plan -var-file=/tmp/terraform.tfvars -out jump -state=/tmp/terraform.state"
        echo "--------------------------------------------------------------------------------------------------------------"
        terraform -chdir=${TERRAFORM_PATH} plan -var-file=/tmp/terraform.tfvars -out jump -state=/tmp/terraform.state
  
        echo "--------------------------------------------------------------------------------------------------------------"
        echo "=> terraform -chdir=${TERRAFORM_PATH} apply -state=/tmp/terraform.tfstate \"jump\""
        terraform -chdir=${TERRAFORM_PATH} apply -state=/tmp/terraform.tfstate "jump"
  
      else
        echo "ERROR: HashiCorp terraform has not been installed, download it from https://www.terraform.io"
        echo "       and install it in /usr/local/bin/terraform"; exit 0
      fi
    else
      messagePrint "Verify vSphere Jump-Server" "$JUMP_HOST"
    fi

    messagePrint " ▪ Wait for SSH to be ready" "< 3m"
    # --- WAIT UNTIL SSH DEAMON IS READY NO JUMPHOST ----
    ret=1
    while [ $ret -ne 0 ]; do
      $SSH_COMMAND -n id > /dev/null 2>&1; ret=$?
      [ $ret -ne 0 ] && sleep 10
    done
  fi

  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ]; then
    JUMP_HOST="jump-${TDH_TKGMC_ENVNAME}.${AWS_HOSTED_DNS_DOMAIN}"

    # --- VERIFY AZURE ACCESS ---
    az ad app list > /dev/null 2>&1
    if [ $? -ne 0 ]; then 
      echo "ERROR: Failed to list Microsoft Azure Applications, please try manually"
      echo "       => az ad app list"
      exit
    fi

    # --- VERIFY / CREATE APPLICATION ID AND SERVICE PRINCIPLE ---
    appid=$(az ad app list --display-name "TanzuDemoHub" | jq -r '.[].appId')
    if [ "$appid" == "" ]; then 
      messageTitle "Register Azure Application (TanzuDemoHub)"
      messagePrint " ▪ Register Azure ApplicationID" "TanzuDemoHub"
      az ad app create --display-name TanzuDemoHub --key-type Password --password tanzu-demo-hub > /dev/null 2>&1
      if [ $? -ne 0 ]; then 
        echo "ERROR: failed to register app (TanzuDemoHub)"
        echo "       => az ad app create --display-name TanzuDemoHub --key-type Password --password tanzu-demo-hub"
        exit
      fi
     
      messagePrint " ▪ Create ServicePrincipal for Application" "TanzuDemoHub"
      appid=$(az ad app list --display-name "TanzuDemoHub" | jq -r '.[].appId')
      az ad sp create --id $appid > /dev/null 2>&1
      if [ $? -ne 0 ]; then 
        echo "ERROR: failed to create ServicePrinicipal for app (TanzuDemoHub)"
        echo "       => az ad sp create --id $appid"
        exit
      fi

      messagePrint " ▪ Create RoleBinding for Application (TanzuDemoHub)" "Owner"
      objid=$(az ad sp list --all --display-name TanzuDemoHub | jq -r '.[].objectId')
      az role assignment create --subscription $AZURE_SUBSCRIPTION_ID --role owner \
          --assignee-principal-type ServicePrincipal --assignee-object-id $objid > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: failed to create RoleBinding for app (TanzuDemoHub)"
        echo "       => az role assignment create --subscription $AZURE_SUBSCRIPTION_ID --role owner \\"
        echo "          --assignee-principal-type ServicePrincipal --assignee-object-id $objid"
        exit
      fi
    fi

    appid=$(az ad app list --display-name "TanzuDemoHub" | jq -r '.[].appId')
    objid=$(az ad sp list --all --display-name TanzuDemoHub | jq -r '.[].objectId')
    messageTitle "Verify Azure Application (TanzuDemoHub)"
    messagePrint " ▪ Application ID" "$appid"
    messagePrint " ▪ Application Display Name" "TanzuDemoHub"
    messagePrint " ▪ ServicePrincipal" "$objid"
    messagePrint " ▪ Role Binding" "Owner"

    messageTitle "Verifing Azure Jump-Server ($JUMP_HOST)"
    stt=$(az group exists --name Admin)
    if [ "$stt" == "false" ]; then
      messagePrint " ▪ Creating Azure Ressource Group" "Admin"
      az group create --name Admin --location $AZURE_LOCATION > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: Creating Ressource Group Admin"
        echo "       => az group create --name Admin --location $AZURE_LOCATION"
        exit 1
      fi
    fi
  
    vm_stt=$(az vm list -d --query "[?contains(name, '$JUMP_HOST')]" | jq -r '.[].powerState')
    if [ "${vm_stt}" == "" ]; then
      # --- VM DOES NOT EXIST, CREATING ---
      nam=$(az network vnet list -g Admin --query "[?contains(name, 'admin-vnet')]" | jq -r '.[].name')
      if [ "$nam" != "admin-vnet" ]; then
        messagePrint " ▪ Creating Vnet" "admin-vnet"

        az network vnet create \
            --resource-group Admin \
            --name admin-vnet \
            --address-prefix 192.168.0.0/16 \
            --subnet-name AdminSubnet \
            --subnet-prefix 192.168.1.0/24 > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Vnet admin-vnet"
          exit 1
        fi
      else
        messagePrint " ▪ Verify Vnet" "admin-vnet"
      fi

      nam=$(az network public-ip list -g Admin --query "[?contains(name, 'AdminPublicIP_$TDH_TKGMC_ENVNAME')]" | jq -r '.[].name')
      if [ "$nam" != "AdminPublicIP_$TDH_TKGMC_ENVNAME" ]; then
        messagePrint " ▪ Creating PublicIP" "AdminPublicIP_$TDH_TKGMC_ENVNAME"

        az network public-ip create \
            --resource-group Admin \
            --name AdminPublicIP_$TDH_TKGMC_ENVNAME  > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating PublicIP AdminPublicIP_$TDH_TKGMC_ENVNAME"
          exit 1
        fi
      else
        pip=$(az network public-ip list -g Admin --query "[?contains(name, 'AdminPublicIP_$TDH_TKGMC_ENVNAME')]" | jq -r '.[].ipAddress')

        messagePrint " ▪ Verify PublicIP (AdminPublicIP_$TDH_TKGMC_ENVNAME)" "$pip"
      fi

      nam=$(az network nsg list --query "[?contains(name, 'AdminSG')]" | jq -r '.[].name')
      if [ "$nam" != "AdminSG" ]; then
        messagePrint " ▪ Creating Security Group" "AdminSG"

        az network nsg create \
            --resource-group Admin \
            --name AdminSG > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group AdminSG"
          exit 1
        fi
      else
        messagePrint " ▪ Verify Security Group" "AdminSG"
      fi

      nam=$(az network nsg rule list -g Admin --nsg-name AdminSG --query "[?contains(name, 'AdminSG-RuleSSH')]" | \
            jq -r '.[].name')
      if [ "$nam" != "AdminSG-RuleSSH" ]; then
        messagePrint " ▪ Creating Security Group Rule" "AdminSG-RuleSSH (22)"

        az network nsg rule create \
            --resource-group Admin \
            --nsg-name AdminSG \
            --name AdminSG-RuleSSH \
            --protocol tcp \
            --priority 1000 \
            --destination-port-range 22 \
            --access allow > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group Rule AdminSG-RuleSSH"
          exit 1
        fi

        messagePrint " ▪ Creating Security Group Rule" "AdminSG-RuleLDAP (636/389)"
        az network nsg rule create \
            --resource-group Admin \
            --nsg-name AdminSG \
            --name AdminSG-RuleLDAP \
            --priority 1001 \
            --destination-port-range 636 389 \
            --access allow > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group Rule AdminSG-RuleLDAP (tcp/636)"
          exit 1
        fi

        messagePrint " ▪ Creating Security Group Rule" "AdminSG-RuleHTTP (80,443)"
        az network nsg rule create \
            --resource-group Admin \
            --nsg-name AdminSG \
            --name AdminSG-RuleHTTP \
            --priority 1002 \
            --destination-port-range 80 443 \
            --access allow > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating Security Group Rule AdminSG-RuleLDAP (tcp/636)"
          exit 1
        fi

      else
        messagePrint " ▪ Verify Security Group Rule" "AdminSG-RuleSSH"
      fi

      nam=$(az network nic list -g Admin --query "[?contains(name, 'AdminNic_$TDH_TKGMC_ENVNAME')]" | \
            jq -r '.[].name')
      if [ "$nam" != "AdminNic_$TDH_TKGMC_ENVNAME" ]; then
        messagePrint " ▪ Creating Nic" "AdminNic_$TDH_TKGMC_ENVNAME"

        az network nic create \
            --resource-group Admin \
            --name AdminNic_$TDH_TKGMC_ENVNAME \
            --vnet-name admin-vnet \
            --subnet AdminSubnet \
            --public-ip-address AdminPublicIP_$TDH_TKGMC_ENVNAME \
            --network-security-group AdminSG > /dev/null 2>&1
        if [ $? -ne 0 ]; then
          echo "ERROR: Creating NIC AdminNic_$TDH_TKGMC_ENVNAME"
          echo "       => az network nic create --resource-group Admin --name AdminNic_$TDH_TKGMC_ENVNAME \\"
          echo "            --vnet-name admin-vnet --subnet AdminSubnet --public-ip-address AdminPublicIP_$TDH_TKGMC_ENVNAME "
          exit 1
        fi
      else
        messagePrint " ▪ Verify NIC" "AdminNic_$TDH_TKGMC_ENVNAME"
      fi

      #nam=$(az vm list --query "[?contains(name, '$JUMP_HOST')]" | jq -r '.[].name')
      #if [ "$nam" != "$JUMP_HOST" ]; then
      messagePrint " ▪ Creating VM" "$JUMP_HOST"

      az vm create \
          --resource-group Admin \
          --name $JUMP_HOST \
          --location $AZURE_LOCATION \
          --nics AdminNic_$TDH_TKGMC_ENVNAME \
          --image UbuntuLTS \
          --admin-username ubuntu \
          --ssh-key-values ~/.tanzu-demo-hub/KeyPair-Azure.pub > /dev/null 2>&1
          #--generate-ssh-keys > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: Creating VM"
        echo "       => az vm create --resource-group Admin --name $JUMP_HOST --location $AZURE_LOCATION \\"
        echo "          --nics AdminNic_$TDH_TKGMC_ENVNAME --image UbuntuLTS --admin-username ubuntu --generate-ssh-keys"
        exit 1
      fi
    else
      #stt=$(az vm list -d --query "[?contains(name, '$JUMP_HOST')]" | jq -r '.[].powerState')
      if [ "${vm_stt}" != "VM running" ]; then
        messagePrint " ▪ Starting VM" "$JUMP_HOST"
        az vm start --resource-group Admin --name $JUMP_HOST
      fi
    fi

    pip=""
    while [ "$pip" == "" -o "$pip" == "null" ]; do
      pip=$(az network public-ip list -g Admin --query "[?contains(name, 'AdminPublicIP_$TDH_TKGMC_ENVNAME')]" | \
            jq -r '.[].ipAddress')
      sleep 10
    done

    aip=$(route53getIPaddress $TDH_TKGMC_ENVNAME $AWS_HOSTED_DNS_DOMAIN)

    # --- UPDATE DNS DOMAIN ---
    if [ "${pip}" != "${aip}" ]; then
      messagePrint " ▪ DNS Zone (${AWS_HOSTED_DNS_DOMAIN})" "zone managed by route53"
      messagePrint " ▪ Updating Zone Record for ($JUMP_HOST)" "$pip"
      route53setDNSrecord "$pip" "$JUMP_HOST" "$AWS_HOSTED_DNS_DOMAIN"
      messagePrint " ▪ Updating Zone Record for (jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN)" "$pip"
      route53setDNSrecord "$pip" "jump.$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN" "$TDH_TKGMC_ENVNAME.$AWS_HOSTED_DNS_DOMAIN"
#jjjjjjjjj az

      sed -in "/$JUMP_HOST/d" ~/.ssh/known_hosts
      messagePrint " ▪ Wait for SSH Daemon on jump-host to come online" "< 5min"
    fi
  fi
}

if [ ! -f /tdh_tools_docker_container  ]; then
  echo ""
  echo "Tanzu Demo Hub - Deploy TCE Management Cluster"
  echo "by Sacha Dubois, VMware Inc,"
  echo "----------------------------------------------------------------------------------------------------------------------------------------------"

  # --- VERIFY TOOLS AND ACCESS ---
  verify_docker
  checkCLIcommands        BASIC
  checkKubernetesServices registry_docker

  if [ $NATIVE -eq 0 ]; then
    # --- CLEANUP IT DELETES ALL CONTAINERS !!! ----
    tdh_tools_build tce

    messagePrint " ▪ Running TDH Tools Docker Container" "tdh-tools-tce:latest $TDHPATH/$CMD_EXEC $CMD_ARGS"
 
    cid=$(docker ps -a | grep tdh-tools-tce:latest | awk '{ print $1 }') 
    [ "$cid" != "" ] && for n in $cid; do docker rm $n -f > /dev/null 2>&1; done

    mkdir -p $HOME/.mc $HOME/.cache $HOME/.config $HOME/.local
    mkdir -p /tmp/docker && chmod a+w /tmp/docker
    docker run -it --rm --name tdh-tools-tce -v /var/run/docker.sock:/var/run/docker.sock tdh-tools-tce:latest chmod 666 /var/run/docker.sock > /dev/null 2>&1
    docker run -u $(id -u):$(id -g) --group-add 0 -it --rm --name tdh-tools-tce --network=host \
       -v $HOME:$HOME:ro -v $HOME/.local:$HOME/.local:rw -v $HOME/.tanzu-demo-hub:$HOME/.tanzu-demo-hub:rw \
       -v /var/run/docker.sock:/var/run/docker.sock:rw -v $HOME/.cache:$HOME/.cache:rw -v $HOME/.config:$HOME/.config:rw \
       -v $HOME/.aws:$HOME/.aws:rw -v $HOME/.vmware-cna-saas:$HOME/.vmware-cna-saas:rw -v $HOME/.azure:$HOME/.azure:rw \
       -v /tmp:/tmp:rw -v /tmp/docker:$HOME/.docker:rw -v $HOME/.mc:$HOME/.mc:rw -v $HOME/.tanzu:$HOME/.tanzu:rw \
       -v $HOME/.kube-tkg:$HOME/.kube-tkg:rw -v $HOME/.kube:$HOME/.kube:rw -v $HOME/.govmomi:$HOME/.govmomi:rw \
       -v $HOME/.ssh:$HOME/.ssh:rw -v $HOME/.terraform:$HOME/.terraform:rw \
       -e "KUBECONFIG=$HOME/.kube/config" --hostname tdh-tools tdh-tools-tce:latest $TDHPATH/$CMD_EXEC $CMD_ARGS; ret=$?

    # --- FINISH CURRENT SESSION AS WE RUN AS CONTAINER ---
    exit $ret
  else
    # --- VERYFY ACCESS TO CLOUD ---
    checkTDHenvironment    

    # --- VERIFY TOOLS AND ACCESS ---
    checkCloudCLI
    checkCLIcommands TOOLS
    checkCLIcommands TKG
    checkCLIcommands TANZU
    checkCLIcommands TMC
    checkCLIcommands VSPHERE
  fi
fi

if [ "$DEPLOY_TKG_CLEAN" -eq 1 ]; then
  cleanupEnvironment

  exit 0
fi

# --- INSTALL TANZU PLUGINS ---
installTanzuPlugins

checkTDHAccess
checkCloudAccess

#checkTMCAccess
#checkTKGdownloads
tmcCheckLogin
checkIdentityProvider

# --- SET MANAGEMENT CLUSTER NAME ---
TDH_TKGMC_NAME=${TDH_TKGMC_NAME}-${TDH_USER}

if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "docker" ]; then
  #########################################################################################################################
  ############################## TANZU COMMNUNITY EDITION MANAGEMENT CLUSTER ON DOCKER ####################################
  #########################################################################################################################

  cnt=$(tanzu management-cluster get 2>/dev/null | grep -c " $TDH_TKGMC_NAME ")
  if [ $cnt -eq 0 ]; then

    # --- CLEANUP KUNECONFIG ---
    cleanupEnvironment
    cleanManagementCluster
    cleanKubeconfig $HOME/.kube/config
    cleanKubeconfig $HOME/.kube-tkg/config
    
    # --- CLEANUP TANZU CONFIG ---
    rm -f $HOME/.config/tanzu/config.yaml

    createTKGMCcluster

    tanzu management-cluster kubeconfig get --admin > /dev/null 2>&1
    kubectl config set-cluster $TDH_TKGMC_NAME > /dev/null 2>&1
    kubectl config use-context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME > /dev/null 2>&1
  fi

  # --- VERIFY TMC REGISTRATION
  tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1
  if [ $? -eq 0 ]; then
    #tmc managementcluster get aws-hosted -o json | jq -r '.status.phase'
    stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json 2>/dev/null | jq -r '.status.conditions.READY.status')
    if [ "$stt" == "FALSE" ]; then
      messagePrint " ▪ TMC ReRegister Cluster"             "$TDH_TKGMC_NAME"
      tmc managementcluster reregister $TDH_TKGMC_NAME -o /tmp/k8s-register-manifest.yaml > /dev/null 2>&1; ret=$?
      if [ $ret -eq 0 ]; then
        kubectl apply -f /tmp/k8s-register-manifest.yaml > /dev/null 2>&1; ret=$?
        if [ $ret -eq 0 ]; then
          messagePrint " ▪ TMC ReRegister Cluster failed, deregister"             "$TDH_TKGMC_NAME"
          tmc managementcluster deregister $TDH_TKGMC_NAME > /dev/null 2>&1
        fi
      fi
    fi
  fi

  tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1
  if [ $? -ne 0 ]; then
    messagePrint " ▪ TMC Register Cluster"             "$TDH_TKGMC_NAME"

    ret=1; cnt=0
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      #tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG --kubeconfig=$HOME/.kube-tkg/config -o /tmp/k8s-register-manifest.yaml >/dev/null 2>&1; ret=$?
      tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG --kubeconfig=$HOME/.kube-tkg/config >/dev/null 2>&1; ret=$?
      if [ $ret -eq 0 ]; then 
        tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1; ret=$?
        if [ $ret -eq 0 ]; then break; else ret=1; fi
      fi
      sleep 30
      let cnt=cnt+1
    done

    if [ $? -ne 0 ]; then
      echo "ERROR: failed to register TCE Management Cluster: $TDH_TKGMC_NAME to TMC"
      echo "       => tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG --kubeconfig=$HOME/.kube-tkg/config"
      exit
    fi

    # NOT NEEDED ANYMORE, WILL VE INSTALLED DURING REGISTRATION (sdubois)
    #messagePrint " ▪ Install TMC Agent in Namespace"             "vmware-system-tmc"
    #if [ $DEBUG -gt 0 ]; then
    #  echo "--------------------------------------------------------------------------------------------------------------"
    #  kubectl apply -f /tmp/k8s-register-manifest.yaml; ret=$?
    #  echo "--------------------------------------------------------------------------------------------------------------"
    #else
    #  kubectl apply -f /tmp/k8s-register-manifest.yaml > /dev/null 2>&1; ret=$?
    #fi
    #
    #if [ $ret -ne 0 ]; then
    #  echo "ERROR: failed to install TMC Agent"
    #  echo "       => kubectl apply -f /tmp/k8s-register-manifest.yaml"
    #fi
    #
    #cnt=0; stt="PENDING"
    #while [ "$stt" != "READY" -a $cnt -lt 10 ]; do
    #  stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json | jq -r '.status.phase')
    #  sleep 60
    #
    #  let cnt=cnt+1
    #done
  fi


else

  #########################################################################################################################
  ############################## TANZU KUBERNETS GRID FOR AWS, AZURE AND VPSHERE (TKGm) ###################################
  #########################################################################################################################

  cnt=$(tanzu management-cluster get 2>/dev/null | grep -c " $TDH_TKGMC_NAME ")
  if [ $cnt -eq 0 ]; then
    # --- ACCEPT LICENSE AGREEMENT ---
    if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ]; then
      messageTitle "Accepting Image Terms for Provider (vmware-inc) / Offer: (tkg-capi)"

      for img in $(az vm image list --publisher vmware-inc --offer tkg-capi --all | jq -r '.[].urn' | \
                   grep -v "2020" | awk -F: '{ printf("%s:%s:%s\n",$1,$2,$3)}' | sort | uniq); do
        stt=$(az vm image terms show --urn $img:latest | jq -r '.accepted')
  
        if [ "$stt" != "true" ]; then 
          messagePrint " ▪ Accepting Image Terms for image ($img)" "$img"

          cnt=0; ret=1
          while [ $ret -ne 0 -a $cnt -lt 5 ]; do
            #az vm image terms accept --urn $img > /dev/null 2>&1; ret=$?
            az vm image terms accept --urn $img:latest; ret=$?
            [ $ret -eq 0 ] && break
            let cnt=cnt+1
            sleep 30
          done

          if [ $ret -ne 0 ]; then 
            echo "ERROR: failed to accept image terms after $cnt tries, please try manually"
            echo "       => az vm image terms accept --urn $img:latest"
            exit
          fi
        fi
      done
    fi

    # --- VERIFY IF DOCKER IS RUNNING ---
    if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ]; then
      docker ps > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: Docker Daemon not running"; exit
        exit 1
      fi
    fi

    # --- CREATE MANAGEMENT CLUSTER ---
    [ ! -d ~/.tanzu-demo-hub/config ] && mkdir -p ~/.tanzu-demo-hub/config
    $SSH_COMMAND -n "[ -f $SSH_HOME/tanzu-demo-hub/scripts/InstallTKGmc.sh ] && tanzu-demo-hub/scripts/InstallTKGmc.sh \"$DEPLOY_TKG_TEMPLATE\" \"$TDH_TKGMC_NAME\" \"$DEBUG\""; ret=$?
    if [ ${ret} -ne 0 ]; then
      echo "ERROR: Failed to deploy Management Server on $JUMP_HOST"
      echo "       => $SSH_DISPLAY -n tanzu-demo-hub/scripts/InstallTKGmc.sh \"$DEPLOY_TKG_TEMPLATE\" \"$DEBUG\""
      exit
    fi

    cleanKubeconfig
    cleanManagementCluster

    # --- LOGIN ---
    tanzu login --server $TDH_TKGMC_NAME > /dev/null 2>&1

    cnt=$(tanzu management-cluster get 2>/dev/null | grep -c " $TDH_TKGMC_NAME ")
    if [ $cnt -eq 0 ]; then
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig ~/.tanzu-demo-hub/config > /dev/null 2>&1
      $SCP_COMMAND ${SSH_USER}@${SSH_HOST}:$SSH_HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml ~/.tanzu-demo-hub/config > /dev/null 2>&1

      # --- UNCOMMENT FOR DEBUGGING ---
      #echo "tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig \
      #  --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME"

      tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig  --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME \
         --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME > /dev/null 2>&1
      tanzu login --server $TDH_TKGMC_NAME > /dev/null 2>&1
      tanzu management-cluster get > /dev/null 2>&1
      if [ $? -ne 0 ]; then
        echo "ERROR: failed to login to TCE Management Cluster: ${TDH_TKGMC_NAME}.kubeconfig"
        echo "       => tanzu login --kubeconfig ~/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.kubeconfig  \\"
        echo "            --name $TDH_TKGMC_NAME --server $TDH_TKGMC_NAME \\"
        echo "            --context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME"
        echo "       => tanzu login --server $TDH_TKGMC_NAME"
        echo "       => tanzu management-cluster get"
        exit
      fi
    fi

    tanzu management-cluster kubeconfig get --admin > /dev/null 2>&1
    kubectl config set-cluster $TDH_TKGMC_NAME > /dev/null 2>&1
    kubectl config use-context ${TDH_TKGMC_NAME}-admin@$TDH_TKGMC_NAME > /dev/null 2>&1
  fi
fi


  # --- VERIFY TMC REGISTRATION
  tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1
  if [ $? -eq 0 ]; then
    #tmc managementcluster get aws-hosted -o json | jq -r '.status.phase'
    stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json 2>/dev/null | jq -r '.status.conditions.READY.status') 
    if [ "$stt" == "FALSE" ]; then 
      messagePrint " ▪ TMC ReRegister Cluster"             "$TDH_TKGMC_NAME"
      tmc managementcluster reregister $TDH_TKGMC_NAME -o /tmp/k8s-register-manifest.yaml > /dev/null 2>&1; ret=$?
      if [ $ret -eq 0 ]; then
        kubectl apply -f /tmp/k8s-register-manifest.yaml > /dev/null 2>&1; ret=$?
        if [ $ret -eq 0 ]; then
          messagePrint " ▪ TMC ReRegister Cluster failed, deregister"             "$TDH_TKGMC_NAME"
          tmc managementcluster deregister $TDH_TKGMC_NAME > /dev/null 2>&1
        fi
      fi
    fi
  fi

  tmc managementcluster get $TDH_TKGMC_NAME > /dev/null 2>&1
  if [ $? -ne 0 ]; then
    messagePrint " ▪ TMC Register Cluster"             "$TDH_TKGMC_NAME"

    ret=1; cnt=0
    while [ $ret -ne 0 -a $cnt -lt 5 ]; do
      tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG -o /tmp/k8s-register-manifest.yaml >/dev/null 2>&1; ret=$?
      [ $ret -eq 0 ] && break
      sleep 30
      let cnt=cnt+1
    done

    if [ $? -ne 0 ]; then
      echo "ERROR: failed to register TCE Management Cluster: $TDH_TKGMC_NAME to TMC"
      echo "       => tmc managementcluster register $TDH_TKGMC_NAME -c tanzu-demo-hub -p TKG"
      exit
    fi

    messagePrint " ▪ Install TMC Agent in Namespace"             "vmware-system-tmc"
    if [ $DEBUG -gt 0 ]; then
      echo "--------------------------------------------------------------------------------------------------------------"
      kubectl apply -f /tmp/k8s-register-manifest.yaml; ret=$?
      echo "--------------------------------------------------------------------------------------------------------------"
    else
      kubectl apply -f /tmp/k8s-register-manifest.yaml > /dev/null 2>&1; ret=$?
    fi

    if [ $ret -ne 0 ]; then
      echo "ERROR: failed to install TMC Agent"
      echo "       => kubectl apply -f /tmp/k8s-register-manifest.yaml"
    fi

    cnt=0; stt="PENDING"
    while [ "$stt" != "READY" -a $cnt -lt 10 ]; do
      stt=$(tmc managementcluster get $TDH_TKGMC_NAME -o json | jq -r '.status.phase') 
      sleep 60
 
      let cnt=cnt+1
    done
  fi

  # --- CLEANUP OLD MANAGEMENT CLUSTERS ---
  #cleanKubeconfig $HOME/.tanzu/config.yaml  => cleanManagementCluster

  messageTitle "Create the TCE Management Cluster deployment File"
  messagePrint " ▪ Deployment File"        "$HOME/.tanzu-demo-hub/config/tkgmc-${TDH_TKGMC_NAME}.yaml"
  messagePrint " ▪ Management Cluster"     "$TDH_TKGMC_NAME"
  messagePrint " ▪ Cloud Infrastructure"   "$TDH_DEPLOYMENT_ENV_NAME"

  mkdir -p $HOME/.tanzu/tkg/clusterconfigs

  DEPLOYMENT_FILE=${HOME}/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.cfg
  TKG_WC_CONFIG_DEV="$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml"
  TKG_WC_CONFIG_PRD="$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml"
  TKG_MC_CONFIG="$HOME/.tanzu-demo-hub/config/${TDH_TKGMC_NAME}.yaml"

  echo "TDH_TKGMC_INFRASTRUCTURE=$TDH_DEPLOYMENT_ENV_NAME"               >  $DEPLOYMENT_FILE
  echo "TDH_TKGMC_NAME=$TDH_TKGMC_NAME"                                  >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_ENVNAME=$TDH_TKGMC_ENVNAME"                            >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_CONFIG=${TDH_TKGMC_NAME}.yaml"                         >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_WC_CONFIG_DEV=${TDH_TKGMC_NAME}-wc-dev.yaml"           >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_WC_CONFIG_PROD=${TDH_TKGMC_NAME}-wc-prod.yaml"         >> $DEPLOYMENT_FILE
  echo "TDH_TKGMC_KUBECONFIG=${TDH_TKGMC_NAME}.kubeconfig"               >> $DEPLOYMENT_FILE

  #echo "TDH_TKGMC_PLAN=dev"                                             >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CEIP_PARTICIPATION=true"                              >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CNI=antrea"                                           >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_LOGLEVEL=1"                                           >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_SERVICE_CIDR=100.64.0.0/13"                           >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CLUSTER_CIDR=100.96.0.0/11"                           >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_MACHINE_HEALTH_CHECK_ENABLED=true"                    >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_MACHINE_TYPE=Standard_D2s_v3"                         >> $DEPLOYMENT_FILE
  #echo "TDH_TKGMC_CONTROL_PLANE_MACHINE_TYPE=Standard_D2s_v3"           >> $DEPLOYMENT_FILE

  messageTitle "Create config file for TCE Workload Clusters"
  messagePrint " ▪ Deployment File (dev)"      "~/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml"
  messagePrint " ▪ Deployment File (prod)"     "~/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml"

  # --- CONFIG FOR PROD AND DEV ---
  idp=$(egrep "^IDENTITY_MANAGEMENT_TYPE:" $TKG_MC_CONFIG | awk '{ print $NF }')
  echo "CLUSTER_PLAN: dev"             >  $TKG_WC_CONFIG_DEV
  echo "CLUSTER_PLAN: prod"            >  $TKG_WC_CONFIG_PRD

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "AWS" ]; then
    var_aws_1="AWS_REGION:|AWS_NODE_AZ:|AWS_ACCESS_KEY_ID:|AWS_SECRET_ACCESS_KEY:|AWS_SSH_KEY_NAME:|AWS_AMI_ID:"
    var_aws_2="CONTROL_PLANE_MACHINE_TYPE:|NODE_MACHINE_TYPE:"

    egrep "$var_aws_1|$var_aws_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_PRD
    egrep "$var_aws_1|$var_aws_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_DEV
  fi

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "vSphere" ]; then
    var_azure_1="AZURE_TENANT_ID:|AZURE_CLIENT_ID:|AZURE_CLIENT_SECRET:|AZURE_SSH_PUBLIC_KEY_B64:|AZURE_CONTROL_PLANE_MACHINE_TYPE:"
    var_azure_2="AZURE_LOCATION:|AZURE_NODE_MACHINE_TYPE:|AZURE_SUBSCRIPTION_ID:"

    egrep "VSPHERE" $TKG_MC_CONFIG | egrep -v "VSPHERE_CONTROL_PLANE_ENDPOINT"     >> $TKG_WC_CONFIG_PRD
    egrep "VSPHERE" $TKG_MC_CONFIG | egrep -v "VSPHERE_CONTROL_PLANE_ENDPOINT"     >> $TKG_WC_CONFIG_DEV
  fi

  if [ "$TDH_DEPLOYMENT_ENV_NAME" == "Azure" ]; then 
    var_azure_1="AZURE_TENANT_ID:|AZURE_CLIENT_ID:|AZURE_CLIENT_SECRET:|AZURE_SSH_PUBLIC_KEY_B64:|AZURE_CONTROL_PLANE_MACHINE_TYPE:"
    var_azure_2="AZURE_LOCATION:|AZURE_NODE_MACHINE_TYPE:|AZURE_SUBSCRIPTION_ID:"

    egrep "$var_azure_1|$var_azure_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_PRD
    egrep "$var_azure_1|$var_azure_2" $TKG_MC_CONFIG     >> $TKG_WC_CONFIG_DEV
  fi
    
  if [ "$idp" == "ldap" ]; then
    var_ldap="LDAP_HOST:|LDAP_GROUP_SEARCH_NAME_ATTRIBUTE:|LDAP_GROUP_SEARCH_USER_ATTRIBUTE:|LDAP_USER_SEARCH_USERNAME:"

    egrep "$var_ldap" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_PRD
    egrep "$var_ldap" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_DEV
  fi

  if [ "$idp" == "oidc" ]; then
    egrep "^OIDC_|IDENTITY_MANAGEMENT_TYPE" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_DEV
    egrep "^OIDC_|IDENTITY_MANAGEMENT_TYPE" $TKG_MC_CONFIG >> $TKG_WC_CONFIG_PRD
  fi

  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ] && CLOUD="vsphere"
  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "Azure" ] && CLOUD="azure"
  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "AWS" ] && CLOUD="aws"
  [ "${TDH_DEPLOYMENT_ENV_NAME}" == "docker" ] && CLOUD="docker"
  
  echo "-----------------------------------------------------------------------------------------------------------"
  #$SSH_COMMAND -n "tanzu management-cluster get 2>/dev/null | sed -n '/^  NAME /,/^NAME/p' | egrep -v \"^NAME\" "
  tanzu config server list 
  echo "-----------------------------------------------------------------------------------------------------------"
  printf "\e[1m1.) Check Management Cluster Status\e[0m\n"
  echo "    => tanzu management-cluster get"
  printf "    => %-80s %s\n" "kubectl config set-cluster ${TDH_TKGMC_NAME}" "# Set k8s Context to mc Cluster"
  printf "    => %-80s %s\n" "kubectl config set-context ${TDH_TKGMC_NAME}-admin@${TDH_TKGMC_NAME}" "# Set k8s Context to mc Cluster"
  printf "    => %-80s %s\n" "kubectl get cluster --all-namespaces" "# Set k8s Context to the TCE Management Cluster"
  printf "    => %-80s %s\n" "kubectl get kubeadmcontrolplane,machine,machinedeployment --all-namespaces" "# To verify the first control plane is up"
  printf "    => %-80s %s\n" "tanzu login --server $TDH_TKGMC_NAME" "# Show Tanzu Management Cluster"
  printf "    => %-80s %s\n" "tanzu management-cluster get" "# Show Tanzu Management Cluster"
  
  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ]; then

    printf "\e[1m2.) Ceeate TCE Workload Cluster\e[0m\n"
    echo "    TCE Workload Cluster 01 ...............................: NAME_TAG: TKG_CLUSTER_01"
    echo "        Cluster Control Plane .............................: $VSPHERE_TKGM_WKLD_CLUSTER01_CONTROL_PLANE"
    echo "        LoadBalancer IP Pool ..............................: $VSPHERE_TKGM_WKLD_CLUSTER01_LOADBALANCER_POOL"
    echo "    TCE Workload Cluster 02 ...............................: NAME_TAG: TKG_CLUSTER_02"
    echo "        Cluster Control Plane .............................: $VSPHERE_TKGM_WKLD_CLUSTER02_CONTROL_PLANE"
    echo "        LoadBalancer IP Pool ..............................: $VSPHERE_TKGM_WKLD_CLUSTER02_LOADBALANCER_POOL"
    echo "    TCE Workload Cluster 03 ...............................: NAME_TAG: TKG_CLUSTER_03"
    echo "        Cluster Control Plane .............................: $VSPHERE_TKGM_WKLD_CLUSTER03_CONTROL_PLANE"
    echo "        LoadBalancer IP Pool ..............................: $VSPHERE_TKGM_WKLD_CLUSTER03_LOADBALANCER_POOL"
    echo ""

    if [ "$NATIVE" == "0" ]; then
      echo "    => tools/$TDH_TOOLS"
      echo "       tdh-tools:/$ export CLUSTER_NAME=<cluster_name>                   ## Workload Cluster Name"
      echo "       tdh-tools:/$ export VSPHERE_CONTROL_PLANE_ENDPOINT=<ip-address>   ## Control Plane IP Adress for the worklaod Cluster"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml --tkr v1.20.4---vmware.3-tkg.1"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml"
      echo "       tdh-tools:/$ tanzu cluster kubeconfig get \$CLUSTER_NAME --admin"
      echo "       tdh-tools:/$ kubectl config use-context \${CLUSTER_NAME}-admin@\$CLUSTER_NAME"
      echo "       tdh-tools:/$ tanzu cluster list --include-management-cluster"
      echo "       tdh-tools:/$ tanzu cluster delete \$CLUSTER_NAME -y"
      echo "       tdh-tools:/$ exit"
    else
      echo "    => export CLUSTER_NAME=<cluster_name>                   ## Workload Cluster Name"
      echo "    => export VSPHERE_CONTROL_PLANE_ENDPOINT=<ip-address>   ## Control Plane IP Adress for the worklaod Cluster"
      echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml --tkr v1.20.4---vmware.3-tkg.1"
      echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml"
      echo "    => tanzu cluster kubeconfig get \$CLUSTER_NAME --admin"
      echo "    => kubectl config use-context \${CLUSTER_NAME}-admin@\$CLUSTER_NAME"
      echo "    => tanzu cluster list --include-management-cluster"
      echo "    => tanzu cluster delete \$CLUSTER_NAME -y"
    fi
  else
    printf "\e[1m2.) Ceeate TCE Workload Cluster\e[0m\n"
    if [ "$NATIVE" == "0" ]; then
      echo "    => tools/$TDH_TOOLS.sh"
      echo "       tdh-tools:/$ tanzu kubernetes-release get"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml  <cluster-name> -tkr v1.18.17---vmware.2-tkg.1"
      echo "       tdh-tools:/$ tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml <cluster-name>"
      echo "       tdh-tools:/$ tanzu cluster kubeconfig get <cluster-name> --admin"
      echo "       tdh-tools:/$ tanzu cluster list --include-management-cluster"
      echo "       tdh-tools:/$ exit"
    else
      echo "    => tanzu kubernetes-release get"
      echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-dev.yaml  <cluster-name> -tkr v1.18.17---vmware.2-tkg.1"
      echo "    => tanzu cluster create -f \$HOME/.tanzu/tkg/clusterconfigs/${TDH_TKGMC_NAME}-wc-prod.yaml <cluster-name>"
      echo "    => tanzu cluster kubeconfig get <cluster-name> --admin"
      echo "    => tanzu cluster list --include-management-cluster"
    fi
  fi

  printf "\e[1m2.) Ceeate Tanzu Demo Hub (TDH) Workload Cluster with services (TBS, Harbor, Ingres etc.)\e[0m\n"
  if [ "${TDH_DEPLOYMENT_ENV_NAME}" == "vSphere" ]; then
    echo "    => ./deployTCE -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -tag TKG_CLUSTER_01"
    echo "    => ./deployTCE -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tdh-$CLOUD-$TDH_USER -tag TKG_CLUSTER_02 -k \"v1.17.16---vmware.2-tkg.1\""
  else
    echo "    => ./deployTCE -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tce-$CLOUD-$TDH_USER"
    echo "    => ./deployTCE -m $TDH_TKGMC_NAME -d tkg-tanzu-demo-hub.cfg -n tce-$CLOUD-$TDH_USER -k \"v1.21.2+vmware.1\""
  fi

#tanzu cluster create tce-docker-sadubois -f /home/tce/.tanzu-demo-hub/config/tce-docker-sadubois.yaml --tkr v1.21.2---vmware.1-tkg.1

  printf "\e[1m3.) Delete the TCE Management Cluster\e[0m\n"
  if [ "$NATIVE" == "0" ]; then
    echo "    => tools/$TDH_TOOLS.sh"
    echo "       tdh-tools:/$ tanzu management-cluster delete $TDH_TKGMC_NAME -y"
    echo "       tdh-tools:/$ exit"
  else
    echo "    => tanzu management-cluster delete $TDH_TKGMC_NAME -y"
  fi
  echo ""
  echo "-----------------------------------------------------------------------------------------------------------"

exit

tanzu management-cluster create -y --file vs1.yaml 

rm -rf $HOME/.config/tanzu
kind get clusters 2>/dev/null | xargs -n1 kind delete cluster --name > /dev/null 2>&1
docker rm -f $(docker ps -aq) > /dev/null 2>&1
docker rmi -f $(docker images -aq) > /dev/null 2>&1
docker system prune --all --volumes -f > /dev/null 2>&1



rm -f /home/tce/.config/tanzu/config.yaml
